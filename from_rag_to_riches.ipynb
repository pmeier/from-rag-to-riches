{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea251428-a6ab-44a1-9c33-652db341f6cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From RAG to riches: Build an AI document interrogation app in 30 mins\n",
    "\n",
    "Philip Meier | PyData Global 2023 | Friday, December 8, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d6210-cf50-4f8e-a71c-fe7328037b65",
   "metadata": {},
   "source": [
    "<img src=\"images/quansight.svg\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b7c42-145c-48b5-9ab8-ea268a42901f",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation (RAG): Make LLMs more useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b42e0-535a-411a-8b1c-40814378b638",
   "metadata": {},
   "source": [
    "LLMs are trained on vast but fixed datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871de8cc-63d0-4494-935f-b7f690ebe22c",
   "metadata": {},
   "source": [
    "![alttext](images/ragna-chatgpt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79180ad-7d87-4dbb-82a7-0937756e3177",
   "metadata": {},
   "source": [
    "There are two ways to inject new data:\n",
    "\n",
    "1. Fine tuning the model on the data\n",
    "2. Adding the data to the prompt\n",
    "\n",
    "RAG is a special case of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b14166-fbeb-40ae-8782-fd712b09212a",
   "metadata": {},
   "source": [
    "![alttext](images/rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff1fe1-ed18-428f-b03e-39e32a5cf3d2",
   "metadata": {},
   "source": [
    "## Ragna\n",
    "\n",
    "Ragna is an extensible queue-backed (This is going to change [soon](https://github.com/Quansight/ragna/pull/205)!) framework that provides:\n",
    "\n",
    "- A **Python API designed for experimentation** that allows you to mix and match the different components of a RAG model (LLMs, vector databases, tokenization strategies, embedding models, etc.) to see their effects on performance and accuracy.\n",
    "- A **REST API that allows you to build RAG-based web applications** or query from other clients like Slack, Mattermost, etc. It wraps around the Python API and provides a consistent developer experience to scale quickly.\n",
    "- A fully featured [Panel](https://panel.holoviz.org/)-based **GUI to select and configure LLMs**, upload documents, and chat with the LLM. For use as an out-of-the-box solution or as a reference to build custom low-code web applications.\n",
    "\n",
    "Install it with\n",
    "\n",
    "```shell\n",
    "pip install 'ragna[all]'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f050c265-5a58-4054-924b-8994acc31aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ragna\n",
    "\n",
    "ragna.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf3b6a-1b96-48f9-b138-77fe47499a66",
   "metadata": {},
   "source": [
    "### Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e889e47-dfd6-4bcc-9f2f-74bac9e574fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragna is a new open source project built by Quansight. It is designed to allow organizations to explore the power of Retrieval-augmented generation (RAG) based AI tools. Ragna provides an intuitive API for quick experimentation and built-in tools for creating production-ready applications allowing you to quickly leverage Large Language Models (LLMs) for your work.\n",
      "\n",
      "At its core, Ragna is a plugin-based framework with a scalable queue based backend that provides:\n",
      "\n",
      " - Python API designed for experimentation that allows you to explore and test different LLMs, vector databases and embedding models quickly in Python.\n",
      "\n",
      "- A REST API that allows you to build custom RAG-based web applications for your particular needs.\n",
      "\n",
      "- A fully featured web application built with Panel (https://panel.holoviz.org) to select and configure LLMs, upload documents, and chat with the LLM. Designed for use as an out-of-the-box solution or as a reference to build custom web applications.\n",
      "\n",
      "The Ragna website is https://ragna.chat/\n",
      "Ragna's source code is available at https://github.com/Quansight/ragna\n",
      "Ragna is licensed under the BSD 3-Clause license\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"documents/ford-10k.pdf\",\n",
    "    \"documents/gm-10k.pdf\",\n",
    "    \"documents/ragna.txt\",\n",
    "]\n",
    "\n",
    "with open(documents[-1]) as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b651c8-45af-474b-a4a7-f0a1746a75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragna import Rag, source_storages, assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb1f232-8d06-4152-a359-a2da577c7fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SourceStorage:\n",
      "  - Chroma\n",
      "  - Ragna/DemoSourceStorage\n",
      "  - LanceDB\n",
      "Assistant:\n",
      "  - Anthropic/claude-2\n",
      "  - Anthropic/claude-instant-1\n",
      "  - Ragna/DemoAssistant\n",
      "  - MosaicML/mpt-7b-instruct\n",
      "  - MosaicML/mpt-30b-instruct\n",
      "  - OpenAI/gpt-4\n",
      "  - OpenAI/gpt-3.5-turbo-16k\n"
     ]
    }
   ],
   "source": [
    "from ragna.core import SourceStorage, Assistant\n",
    "\n",
    "for base_cls, module in [\n",
    "    (SourceStorage, source_storages),\n",
    "    (Assistant, assistants),\n",
    "]:\n",
    "    print(f\"{base_cls.__name__}:\")\n",
    "    for cls in module.__dict__.values():\n",
    "        if isinstance(cls, type) and issubclass(cls, base_cls):\n",
    "            print(f\"  - {cls.display_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661ea920-8f3b-4f29-993b-5b415445b4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "assert dotenv.load_dotenv()\n",
    "assert \"OPENAI_API_KEY\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2f4a3b-bc66-42ec-bc5f-42c926bf29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = Rag()\n",
    "chat = rag.chat(\n",
    "    documents=documents,\n",
    "    source_storage=source_storages.Chroma,\n",
    "    assistant=assistants.Gpt35Turbo16k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3f247c-dbca-40cc-a521-bc3dae809aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content='How can I help you with the documents?', role=<MessageRole.SYSTEM: 'system'>, sources=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fc7586-2aab-4b5e-8c35-4eba83e9a081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ragna framework is an open source project developed by Quansight. It is designed to enable organizations to explore the capabilities of Retrieval-augmented generation (RAG) based AI tools. Ragna provides a plugin-based framework with a scalable queue-based backend. It offers a Python API for experimentation with different Large Language Models (LLMs), vector databases, and embedding models. Additionally, Ragna provides a REST API for building custom RAG-based web applications and a fully featured web application built with Panel for selecting and configuring LLMs, uploading documents, and interacting with the LLM. It can be used as an out-of-the-box solution or as a reference for building custom web applications.\n"
     ]
    }
   ],
   "source": [
    "answer = await chat.answer(\"What is the Ragna framework?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79ccda3c-f99d-424e-9723-b943c3c2bcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ragna.txt, \n",
      "2. ford-10k.pdf, 173, 174\n"
     ]
    }
   ],
   "source": [
    "for idx, source in enumerate(answer.sources, 1):\n",
    "    print(f\"{idx}. {source.document.name}, {source.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151ef2b-5827-499b-8a87-ece12b4f3e4e",
   "metadata": {},
   "source": [
    "### REST API / Web UI\n",
    "\n",
    "[`tryragna.ipynb`](tryragna.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c3473-d9b4-4a2c-96c5-5e212a921195",
   "metadata": {},
   "source": [
    "## Extending Ragna with a local LLM\n",
    "\n",
    "[`local_llm.py`](local_llm.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017329cd-f7d4-4aca-9d1a-c3407310ce92",
   "metadata": {},
   "source": [
    "### Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17eec472-b1f7-4c4b-8ed3-da23bf397d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import local_llm\n",
    "\n",
    "assert local_llm.Airoboros.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3980c5e7-5541-47ca-9cd7-53e7b5057c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping module injection for FusedLlamaMLPForQuantizedModel as currently not supported with use_triton=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragna is a framework designed to allow organizations to explore the power of Retrieval-augmented generation (RAG) based AI tools. It provides an intuitive API for quick experimentation and built-in tools for creating production-ready applications.\n"
     ]
    }
   ],
   "source": [
    "async with rag.chat(\n",
    "    documents=documents,\n",
    "    source_storage=source_storages.Chroma,\n",
    "    assistant=local_llm.Airoboros,\n",
    ") as chat:\n",
    "    print(await chat.answer(\"What is the Ragna framework?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fced8672-e445-4ed9-ac63-4d1e1d8f303a",
   "metadata": {},
   "source": [
    "### REST API / Web UI\n",
    "\n",
    "```shell\n",
    "$ ragna init\n",
    "```\n",
    "\n",
    "[`ragna.toml`](ragna.toml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577aab50-2d29-4b36-a447-f09810e4a836",
   "metadata": {
    "tags": []
   },
   "source": [
    "```shell\n",
    "$ ragna ui --config ragna.toml\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
